import jsonã…‡
from datetime import datetime
from io import BytesIO

import streamlit as st
import streamlit.components.v1 as components
import google.generativeai as genai
from PIL import Image

try:
    import docx
    DOCX_OK = True
except Exception:
    DOCX_OK = False

try:
    from pypdf import PdfReader
    PDF_OK = True
except Exception:
    PDF_OK = False


st.set_page_config(page_title="hwahwago_translator", layout="wide")

if "history" not in st.session_state:
    st.session_state.history = []
if "vocab" not in st.session_state:
    st.session_state.vocab = []
if "last_source" not in st.session_state:
    st.session_state.last_source = ""
if "last_output" not in st.session_state:
    st.session_state.last_output = ""


def now_str():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def add_vocab_item(kind: str, text: str, note: str = ""):
    text = (text or "").strip()
    if not text:
        return
    item = {
        "time": now_str(),
        "kind": kind,
        "text": text,
        "note": (note or "").strip(),
    }
    st.session_state.vocab.append(item)


def download_bytes(filename: str, data: bytes, mime: str):
    st.download_button(
        label=f"ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ",
        data=data,
        file_name=filename,
        mime=mime,
        use_container_width=True,
    )


def safe_decode(b: bytes) -> str:
    for enc in ("utf-8", "utf-8-sig", "cp949", "euc-kr", "latin-1"):
        try:
            return b.decode(enc)
        except Exception:
            pass
    return b.decode("utf-8", errors="ignore")


def read_txt(uploaded) -> str:
    return safe_decode(uploaded.getvalue())


def read_docx(uploaded) -> str:
    if not DOCX_OK:
        raise RuntimeError("python-docxê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    f = BytesIO(uploaded.getvalue())
    d = docx.Document(f)
    parts = []
    for p in d.paragraphs:
        parts.append(p.text)
    return "\n".join(parts).strip()


def read_pdf(uploaded) -> str:
    if not PDF_OK:
        raise RuntimeError("pypdfê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    f = BytesIO(uploaded.getvalue())
    reader = PdfReader(f)
    parts = []
    for page in reader.pages:
        parts.append(page.extract_text() or "")
    return "\n".join(parts).strip()


def chunk_text(text: str, max_chars: int = 8000):
    text = text or ""
    if len(text) <= max_chars:
        return [text]
    chunks = []
    cur = []
    cur_len = 0
    for line in text.splitlines(True):
        if cur_len + len(line) > max_chars and cur:
            chunks.append("".join(cur))
            cur = []
            cur_len = 0
        cur.append(line)
        cur_len += len(line)
    if cur:
        chunks.append("".join(cur))
    return chunks


def get_api_key():
    if "GEMINI_API_KEY" in st.secrets and str(st.secrets.get("GEMINI_API_KEY")).strip():
        return str(st.secrets.get("GEMINI_API_KEY")).strip(), True
    return "", False


def init_model(api_key: str, model_name: str):
    genai.configure(api_key=api_key)
    return genai.GenerativeModel(model_name)


def gemini_text(model, prompt: str) -> str:
    res = model.generate_content(prompt)
    return getattr(res, "text", "") or ""


def gemini_image(model, prompt: str, image: Image.Image) -> str:
    res = model.generate_content([prompt, image])
    return getattr(res, "text", "") or ""


with st.sidebar:
    st.title("ğŸ› ï¸ ê¸°ëŠ¥íˆ´")

    secret_key, loaded_from_secrets = get_api_key()
    if loaded_from_secrets:
        st.success("APIë¡œë“œ ë¨")
        api_key = secret_key
    else:
        api_key = st.text_input("Gemini API Key ì…ë ¥", type="password")

    st.divider()

    TARGET_LANGS = ["í•œêµ­ì–´", "ë² íŠ¸ë‚¨ì–´", "ì¼ë³¸ì–´", "ì˜ì–´", "ì¤‘êµ­ì–´"]
    lang = st.selectbox("ëª©í‘œ ì–¸ì–´", TARGET_LANGS, index=0)

    mode = st.radio("ëª¨ë“œ", ["ë²ˆì—­", "í•´ì„(ì˜ë¯¸ ì¤‘ì‹¬)"], horizontal=True)

    tone = st.selectbox("í†¤", ["ê¸°ë³¸", "ê³µì†", "ìºì£¼ì–¼", "ë¹„ì¦ˆë‹ˆìŠ¤", "í•™ìˆ "], index=0)

    keep_format = st.toggle("ì¤„ë°”ê¿ˆ/í˜•ì‹ ìœ ì§€", value=True)

    st.divider()
    st.subheader("ğŸ“š ë‹¨ì–´ì¥")
    st.caption(f"ì €ì¥ ê°œìˆ˜: {len(st.session_state.vocab)}")
    col_v1, col_v2 = st.columns(2)
    with col_v1:
        if st.button("ë‹¨ì–´ì¥ ë³´ê¸°", use_container_width=True):
            st.session_state._show_vocab = True
    with col_v2:
        vocab_json = json.dumps(st.session_state.vocab, ensure_ascii=False, indent=2).encode("utf-8")
        st.download_button(
            "ë‹¨ì–´ì¥ JSON ë‹¤ìš´ë¡œë“œ",
            data=vocab_json,
            file_name="vocab.json",
            mime="application/json",
            use_container_width=True,
        )

st.title("ğŸŒ ë²ˆì—­ê¸°")



if not api_key:
    st.warning("ì‚¬ì´ë“œë°”ì— Gemini API í‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. (Streamlit Cloudì—ì„œëŠ” Secretsì— ë„£ìœ¼ë©´ ì…ë ¥ ì—†ì´ ë™ì‘)")
    st.stop()

try:
    model = init_model(api_key, "gemini-2.5-flash-lite")
except Exception as e:
    st.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    st.stop()


def build_prompt(target_lang: str, user_text: str) -> str:
    base = []
    if mode == "ë²ˆì—­":
        base.append(f"ë‹¤ìŒ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ¬ìš´ {target_lang}ë¡œ ë²ˆì—­í•´ì¤˜.")
    else:
        base.append(f"ë‹¤ìŒ ë‚´ìš©ì„ {target_lang}ë¡œ ì´í•´í•˜ê¸° ì‰½ê²Œ í•´ì„í•´ì¤˜. ì§ì—­ë³´ë‹¤ ì˜ë¯¸ ì „ë‹¬ì— ì§‘ì¤‘í•´ì¤˜.")
    if tone != "ê¸°ë³¸":
        base.append(f"í†¤ì€ '{tone}'ë¡œ ë§ì¶°ì¤˜.")
    if keep_format:
        base.append("ì›ë¬¸ì˜ ì¤„ë°”ê¿ˆ/ëª©ë¡/í˜•ì‹ì„ ìµœëŒ€í•œ ìœ ì§€í•´ì¤˜.")
    base.append("")
    base.append(user_text)
    return "\n".join(base).strip()


def run_text_job(text: str) -> str:
    chunks = chunk_text(text, max_chars=8000)
    outs = []
    for i, ch in enumerate(chunks, start=1):
        prompt = build_prompt(lang, ch)
        out = gemini_text(model, prompt)
        if len(chunks) > 1:
            outs.append(f"[íŒŒíŠ¸ {i}/{len(chunks)}]\n{out}".strip())
        else:
            outs.append(out.strip())
    return "\n\n".join([o for o in outs if o]).strip()


tab_text, tab_file, tab_img, tab_voice = st.tabs(
    ["ğŸ“ í…ìŠ¤íŠ¸ ì…ë ¥", "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ(TXT/DOCX/PDF)", "ğŸ“· ì‚¬ì§„ ë²ˆì—­", "ğŸ™ï¸ ìŒì„± ì¸ì‹"]
)

with tab_text:
    source = st.text_area("ë‚´ìš© ì…ë ¥", height=280)
    col_a, col_b = st.columns([1, 1])
    with col_a:
        run_btn = st.button("ì‹¤í–‰ ğŸš€", use_container_width=True)
    with col_b:
        save_btn = st.button("ğŸ“Œ ê²°ê³¼ë¥¼ ë‹¨ì–´ì¥ì— ì €ì¥", use_container_width=True)

    if run_btn and source.strip():
        with st.spinner("ì²˜ë¦¬ ì¤‘..."):
            try:
                out = run_text_job(source)
                st.session_state.last_source = source
                st.session_state.last_output = out
                st.session_state.history.append(
                    {"time": now_str(), "type": "text", "lang": lang, "mode": mode, "tone": tone, "source": source, "output": out}
                )
                st.success(out)
            except Exception as e:
                st.error(f"ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    if save_btn:
        if st.session_state.last_output.strip():
            add_vocab_item("result", st.session_state.last_output, note=f"{lang} / {mode} / {tone}")
            st.success("ë‹¨ì–´ì¥ì— ì €ì¥í–ˆì–´ìš”.")
        else:
            st.info("ì €ì¥í•  ê²°ê³¼ê°€ ì—†ì–´ìš”. ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")

    if st.session_state.last_output.strip():
        st.divider()
        out_txt = st.session_state.last_output
        if st.button("ğŸ“¤ ë²ˆì—­ ê²°ê³¼ TXTë¡œ ë‹¤ìš´ë¡œë“œ", use_container_width=True):
            download_bytes("translation.txt", out_txt.encode("utf-8"), "text/plain")

with tab_file:
    st.caption("TXT/DOCX/PDF íŒŒì¼ì„ ì˜¬ë¦¬ë©´ ë‚´ìš©ì„ ì¶”ì¶œí•´ì„œ ë²ˆì—­/í•´ì„í•©ë‹ˆë‹¤.")
    uploaded = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["txt", "docx", "pdf"])
    col_f1, col_f2 = st.columns([1, 1])
    with col_f1:
        run_file = st.button("íŒŒì¼ ì‹¤í–‰ ğŸš€", use_container_width=True)
    with col_f2:
        save_file_result = st.button("ğŸ“Œ íŒŒì¼ ê²°ê³¼ ë‹¨ì–´ì¥ ì €ì¥", use_container_width=True)

    file_text = ""
    file_name = ""
    if uploaded:
        file_name = uploaded.name
        try:
            if file_name.lower().endswith(".txt"):
                file_text = read_txt(uploaded)
            elif file_name.lower().endswith(".docx"):
                file_text = read_docx(uploaded)
            elif file_name.lower().endswith(".pdf"):
                file_text = read_pdf(uploaded)
            else:
                st.warning("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

    if uploaded and file_text:
        with st.expander("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
            st.text_area("ë¯¸ë¦¬ë³´ê¸°", file_text[:20000], height=220)

    if run_file and uploaded and file_text:
        with st.spinner("íŒŒì¼ ë²ˆì—­ ì¤‘..."):
            try:
                out = run_text_job(file_text)
                st.session_state.last_source = f"[FILE:{file_name}]\n\n{file_text}"
                st.session_state.last_output = out
                st.session_state.history.append(
                    {"time": now_str(), "type": "file", "file": file_name, "lang": lang, "mode": mode, "tone": tone, "source": file_text, "output": out}
                )
                st.success(out)
            except Exception as e:
                st.error(f"íŒŒì¼ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    if save_file_result:
        if st.session_state.last_output.strip():
            add_vocab_item("file_result", st.session_state.last_output, note=f"{lang} / {mode} / {tone}")
            st.success("ë‹¨ì–´ì¥ì— ì €ì¥í–ˆì–´ìš”.")
        else:
            st.info("ì €ì¥í•  ê²°ê³¼ê°€ ì—†ì–´ìš”. ë¨¼ì € íŒŒì¼ ì‹¤í–‰ì„ í•´ ì£¼ì„¸ìš”.")

    if st.session_state.last_output.strip():
        st.divider()
        out_txt = st.session_state.last_output
        st.caption("ë‹¤ìš´ë¡œë“œ í˜•ì‹")
        dl_col1, dl_col2 = st.columns(2)
        with dl_col1:
            download_bytes("translation.txt", out_txt.encode("utf-8"), "text/plain")
        with dl_col2:
            download_bytes("translation.json", json.dumps({"output": out_txt}, ensure_ascii=False, indent=2).encode("utf-8"), "application/json")

with tab_img:
    st.subheader("ğŸ“· ì‚¬ì§„ ë²ˆì—­ (OCR + ë²ˆì—­)")
    img_file = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["png", "jpg", "jpeg", "webp"])
    run_img = st.button("ì‚¬ì§„ ë²ˆì—­ ì‹¤í–‰ ğŸ“·", use_container_width=True)

    if img_file:
        image = Image.open(img_file).convert("RGB")
        st.image(image, use_container_width=True)

        if run_img:
            with st.spinner("ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘..."):
                try:
                    prompt = f"""
You are an OCR + Translation Assistant.

Extract the text within the image as accurately as possible.
Translate the extracted text into natural {lang} {'translation' if mode=='translation' else 'interpretation (meaning-focused)'}.
Match the tone to '{tone}'.
Output in the following format:

[ì¶”ì¶œ í…ìŠ¤íŠ¸]
...

[ê²°ê³¼]
...
"""
                    out = gemini_image(model, prompt.strip(), image)
                    st.session_state.last_source = f"[IMAGE:{img_file.name}]"
                    st.session_state.last_output = out
                    st.session_state.history.append(
                        {"time": now_str(), "type": "image", "file": img_file.name, "lang": lang, "mode": mode, "tone": tone, "source": "(image)", "output": out}
                    )
                    st.success(out)
                except Exception as e:
                    st.error(f"ì‚¬ì§„ ë²ˆì—­ ì‹¤íŒ¨: {e}")

    if st.session_state.last_output.strip():
        st.divider()
        out_txt = st.session_state.last_output
        download_bytes("image_translation.txt", out_txt.encode("utf-8"), "text/plain")

# âœ… tab_voice ë¸”ë¡ì„ ì•„ë˜ ì½”ë“œë¡œ "í†µì§¸ë¡œ êµì²´"í•˜ë©´ ë¼
with tab_voice:
    st.subheader("ğŸ™ï¸ ìŒì„± ì¸ì‹")
    st.caption("ğŸ”´ ë“£ëŠ” ì¤‘ í‘œì‹œ + 10ì´ˆ ë¬´ìŒ ê²½ê³  + 1ë¶„ ë¬´ìŒ ìë™ ì •ì§€")

    components.html(
        """
        <div style="font-family: sans-serif; display:flex; flex-direction:column; gap:10px;">
          <div style="display:flex; gap:8px; flex-wrap:wrap; align-items:center;">
            <button id="start" style="padding:8px 12px;">ğŸ™ï¸ ì‹œì‘</button>
            <button id="stop" style="padding:8px 12px;" disabled>â¹ï¸ ì¤‘ì§€</button>

            <select id="lang" style="padding:8px 12px;">
              <option value="ko-KR" selected>í•œêµ­ì–´</option>
              <option value="en-US">ì˜ì–´</option>
              <option value="ja-JP">ì¼ë³¸ì–´</option>
              <option value="vi-VN">ë² íŠ¸ë‚¨ì–´</option>
              <option value="zh-CN">ì¤‘êµ­ì–´</option>
            </select>
          </div>

          <div id="status"
               style="padding:10px 12px; border-radius:10px; background:#f3f4f6; border:1px solid #e5e7eb;">
            âšªï¸ ëŒ€ê¸° ì¤‘
          </div>

          <textarea id="out" style="width:100%; height:220px; padding:10px;" placeholder="ì—¬ê¸°ì— ì¸ì‹ í…ìŠ¤íŠ¸ê°€ í‘œì‹œë©ë‹ˆë‹¤..."></textarea>

          <div style="display:flex; gap:8px; flex-wrap:wrap;">
            <button id="copy" style="padding:8px 12px;">ğŸ“‹ ë³µì‚¬</button>
            <button id="clear" style="padding:8px 12px;">ğŸ§¹ ì§€ìš°ê¸°</button>
          </div>

          <div style="opacity:.75; font-size:12px;">
            * 10ì´ˆ ë™ì•ˆ ê²°ê³¼ê°€ ì•ˆ ë“¤ì–´ì˜¤ë©´ â€œì†Œë¦¬ê°€ ë“¤ë¦¬ì§€ ì•Šì•„ìš”â€ í‘œì‹œ<br/>
            * 1ë¶„ ë™ì•ˆ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¤‘ì§€ë©ë‹ˆë‹¤
          </div>
        </div>

        <script>
          const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

          const startBtn = document.getElementById("start");
          const stopBtn  = document.getElementById("stop");
          const copyBtn  = document.getElementById("copy");
          const clearBtn = document.getElementById("clear");
          const langSel  = document.getElementById("lang");
          const out      = document.getElementById("out");
          const statusEl = document.getElementById("status");

          let rec = null;
          let listening = false;

          // ë§ˆì§€ë§‰ìœ¼ë¡œ "ì¸ì‹ ê²°ê³¼"ê°€ ë“¤ì–´ì˜¨ ì‹œê°„ (ë¬´ìŒ íŒë‹¨ ê¸°ì¤€)
          let lastHeardMs = 0;

          // íƒ€ì´ë¨¸(ìƒíƒœ ì—…ë°ì´íŠ¸)
          let tickId = null;

          function setStatus(text, kind){
            // kind: idle | listening | warn | stopped | error
            let bg = "#f3f4f6", bd="#e5e7eb";
            if(kind === "listening"){ bg="#ecfeff"; bd="#a5f3fc"; }
            if(kind === "warn"){ bg="#fffbeb"; bd="#fde68a"; }
            if(kind === "stopped"){ bg="#f3f4f6"; bd="#e5e7eb"; }
            if(kind === "error"){ bg="#fef2f2"; bd="#fecaca"; }
            statusEl.style.background = bg;
            statusEl.style.borderColor = bd;
            statusEl.textContent = text;
          }

          function setButtons(){
            startBtn.disabled = listening;
            stopBtn.disabled  = !listening;
          }

          function stopListening(auto=false){
            if(rec){
              try { rec.stop(); } catch(e) {}
            }
            listening = false;
            setButtons();
            if(auto){
              setStatus("â¹ï¸ 1ë¶„ ë™ì•ˆ ì†Œë¦¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•„ ìë™ìœ¼ë¡œ ì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.", "stopped");
            } else {
              setStatus("âš«ï¸ ì¤‘ì§€ë¨", "stopped");
            }
            if(tickId){
              clearInterval(tickId);
              tickId = null;
            }
          }

          function startListening(){
            if(!rec) return;

            listening = true;
            lastHeardMs = Date.now(); // ì‹œì‘ ì‹œì  ê¸°ì¤€ìœ¼ë¡œ íƒ€ì´ë¨¸ ì‹œì‘
            setButtons();
            setStatus("ğŸ”´ ë“£ëŠ” ì¤‘â€¦", "listening");

            try { rec.start(); } catch(e) {}

            // 0.5ì´ˆë§ˆë‹¤ ë¬´ìŒ ì²´í¬
            tickId = setInterval(() => {
              if(!listening) return;

              const elapsed = Date.now() - lastHeardMs;

              // 10ì´ˆ ë¬´ìŒ ê²½ê³ 
              if(elapsed >= 10000 && elapsed < 60000){
                setStatus("âš ï¸ ì†Œë¦¬ê°€ ë“¤ë¦¬ì§€ ì•Šì•„ìš” (ë§ˆì´í¬/ì£¼ë³€ ì†ŒìŒ/ê¶Œí•œì„ í™•ì¸í•´ ì£¼ì„¸ìš”)", "warn");
              }

              // 1ë¶„ ë¬´ìŒ ìë™ ì •ì§€
              if(elapsed >= 60000){
                stopListening(true);
              }
            }, 500);
          }

          if(!SpeechRecognition){
            setStatus("âŒ ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í¬ë¡¬/ì—£ì§€ë¡œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "error");
            startBtn.disabled = true;
            stopBtn.disabled = true;
          } else {
            rec = new SpeechRecognition();
            rec.lang = langSel.value;
            rec.interimResults = true;
            rec.continuous = true;

            langSel.onchange = () => {
              if(rec) rec.lang = langSel.value;
            };

            // ì¸ì‹ ê²°ê³¼ê°€ ë“¤ì–´ì˜¤ë©´ "ì†Œë¦¬ê°€ ë“¤ë ¸ë‹¤"ë¡œ íŒë‹¨í•˜ê³  íƒ€ì´ë¨¸ ë¦¬ì…‹
            rec.onresult = (e) => {
              let text = "";
              for(let i=0; i<e.results.length; i++){
                text += e.results[i][0].transcript;
              }
              out.value = text;

              // âœ… ì—¬ê¸°ì„œ ë§ˆì§€ë§‰ ì…ë ¥ ì‹œê°„ì„ ê°±ì‹  â†’ ë¬´ìŒ íƒ€ì´ë¨¸ ë¦¬ì…‹
              lastHeardMs = Date.now();

              // ë“£ëŠ” ì¤‘ í‘œì‹œë¡œ ë³µê·€
              if(listening){
                setStatus("ğŸ”´ ë“£ëŠ” ì¤‘â€¦", "listening");
              }
            };

            // ì‚¬ìš©ìê°€ ê¶Œí•œì„ ë§‰ì•˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë‚˜ë©´ ìƒíƒœ í‘œì‹œ
            rec.onerror = (e) => {
              // e.error: "not-allowed", "service-not-allowed", "no-speech" ë“±
              listening = false;
              setButtons();
              if(tickId){
                clearInterval(tickId);
                tickId = null;
              }
              if(e && e.error === "not-allowed"){
                setStatus("âŒ ë§ˆì´í¬ ê¶Œí•œì´ ì°¨ë‹¨ë˜ì–´ ìˆì–´ìš”. ì£¼ì†Œì°½ ì™¼ìª½ ìë¬¼ì‡ ì—ì„œ ë§ˆì´í¬ í—ˆìš© í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "error");
              } else if(e && e.error === "no-speech"){
                setStatus("âš ï¸ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ì–´ìš”. ë§ˆì´í¬ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.", "warn");
              } else {
                setStatus("âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: " + (e && e.error ? e.error : "unknown"), "error");
              }
            };

            rec.onend = () => {
              // ì‚¬ìš©ìê°€ stopì„ ëˆŒë €ê±°ë‚˜ ë¸Œë¼ìš°ì €ê°€ ì¢…ë£Œí–ˆì„ ë•Œ
              // listeningì´ trueì¸ ìƒíƒœë¡œ endê°€ ì˜¤ë©´(ì¼ì‹œì  ì¢…ë£Œ)ë„ ìˆì„ ìˆ˜ ìˆì–´ì„œ
              // ì—¬ê¸°ì„œëŠ” ë²„íŠ¼ ìƒíƒœë§Œ ì•ˆì „í•˜ê²Œ ë§ì¶°ì¤Œ
              if(listening){
                // ì¼ë¶€ ë¸Œë¼ìš°ì €ì—ì„œ ì—°ì† ì¸ì‹ ì¤‘ê°„ì— endê°€ ë°œìƒí•˜ê¸°ë„ í•¨
                // ë„ˆë¬´ ê³µê²©ì ìœ¼ë¡œ ì¬ì‹œì‘í•˜ë©´ UXê°€ ì´ìƒí•´ì ¸ì„œ, ì‚¬ìš©ìê°€ ë‹¤ì‹œ ì‹œì‘í•˜ë„ë¡ ë‘ 
                listening = false;
                setButtons();
                if(tickId){
                  clearInterval(tickId);
                  tickId = null;
                }
                setStatus("âš«ï¸ ì¤‘ì§€ë¨ (ë¸Œë¼ìš°ì €ê°€ ì¸ì‹ì„ ì¢…ë£Œí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œì‘ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”)", "stopped");
              }
            };

            startBtn.onclick = () => startListening();
            stopBtn.onclick  = () => stopListening(false);

            copyBtn.onclick = async () => {
              try { await navigator.clipboard.writeText(out.value || ""); } catch(e) {}
            };

            clearBtn.onclick = () => {
              out.value = "";
              // í…ìŠ¤íŠ¸ë¥¼ ì§€ìš°ëŠ” ê±´ "ë¬´ìŒ"ì´ë‘ ë³„ê°œë¼ì„œ íƒ€ì´ë¨¸ëŠ” ê·¸ëŒ€ë¡œ ë‘ 
            };

            setButtons();
            setStatus("âšªï¸ ëŒ€ê¸° ì¤‘", "idle");
          }
        </script>
        """,
        height=420,
    )

